{"cells":[{"cell_type":"markdown","source":["## **EXERCÍCIO 04 - Transformers**\n","\n","## **CESAR SCHOOL**\n","* Pós-graduação em Engenharia e Análise de Dados - 2023.2\n","* **Disciplina: Tópicos Complementares**\n","* Professor: **Silvan Ferreira**\n","* Aluno: **Allan Bispo** - apsb@cesar.school"],"metadata":{"id":"XQ43kG3SI0JO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8Y7I1EnIpgw"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJPh_c9qIpgy"},"outputs":[],"source":["d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlgSMsOuIpgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723949458469,"user_tz":180,"elapsed":14,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"c9b3d935-d8da-4114-88d2-44db0e1edbcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 32, 512])\n"]}],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :]\n","\n","# Exemplo\n","max_len = 100\n","pos_encoding = PositionalEncoding(d_model, max_len)\n","\n","# (sequence_length, batch_size, d_model)\n","input_tensor = torch.randn(50, batch_size, d_model)\n","output_tensor = pos_encoding(input_tensor)\n","\n","print(output_tensor.shape)  # Output shape: (sequence_length, batch_size, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TKGhAS6Ipg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723949458469,"user_tz":180,"elapsed":12,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"69425f2d-64cd-438d-ba20-832bd9844063"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        # Verifica se o número de dimensões do modelo é divisível pelo número de cabeças\n","        assert d_model % num_heads == 0\n","\n","        # Número de dimensões por cabeça\n","        self.d_k = d_model // num_heads\n","        self.num_heads = num_heads\n","\n","        # Inicializa as camadas lineares para Q, K e V\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # Calcula os scores fazendo o produto escalar entre Q e K e dividindo pela raiz quadrada de d_k\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        # Se a máscara for fornecida, aplica a máscara para os scores\n","        if mask is not None:\n","            scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","        # Calcula a softmax nos scores\n","        attention = torch.softmax(scores                    , dim=-1)\n","\n","        # Multiplica a matriz de atenção pelo valor V\n","        output = torch.matmul(attention, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        # Divide a última dimensão em (num_heads, d_k)\n","        N, seq_len, d_model = x.size()\n","        return x.view(N, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        # Inverte a operação de split_heads\n","        N, _, seq_len, _ = x.size()\n","        return x.transpose(1, 2).contiguous().view(N, seq_len, self.num_heads * self.d_k)\n","\n","    def forward(self, query, key, value, mask=None):\n","        N = query.shape[0]\n","        query_len, key_len, value_len = query.shape[1], key.shape[1], value.shape[1]\n","\n","        # Passa os valores de Q, K e V pela camada linear\n","        Q = self.split_heads(self.W_q(query))\n","        K = self.split_heads(self.W_k(key))\n","        V = self.split_heads(self.W_v(value))\n","\n","        # Calcula a atenção\n","        attention = self.scaled_dot_product_attention(Q, K, V, mask)\n","\n","        # Combina as cabeças e aplica a camada linear final\n","        output = self.combine_heads(attention)\n","        output = self.W_o(output)\n","        return output\n","\n","\n","multi_head_attn = MultiHeadAttention(d_model, num_heads)\n","\n","# (batch_size, sequence_length, d_model)\n","query = torch.randn(batch_size, 50, d_model)\n","key = torch.randn(batch_size, 50, d_model)\n","value = torch.randn(batch_size, 50, d_model)\n","\n","output = multi_head_attn(query, key, value)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsSoF2G_Ipg1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723949458864,"user_tz":180,"elapsed":404,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"e3da93ad-42dc-47dd-ea8b-54539eb7e105"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))\n","\n","\n","d_model = 512\n","d_ff = 2048\n","ffn = FeedForward(d_model, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = ffn(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64KWhVr5Ipg1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723949458865,"user_tz":180,"elapsed":11,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"3e0b988e-af1e-48f2-89e5-7b7162cfb046"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        attn_output = self.attention(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ffn_output = self.ffn(x)\n","        x = self.norm2(x + self.dropout(ffn_output))\n","        return x\n","\n","\n","encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = encoder_layer(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwvFqKvnIpg1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723949462707,"user_tz":180,"elapsed":3850,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"c9eee926-f332-4c54-bae5-5422a963ab31"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 512])\n"]}],"source":["class Encoder(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return x\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = encoder(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","source":["output.mean(dim=1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adQDQQhAZD-7","executionInfo":{"status":"ok","timestamp":1723949465623,"user_tz":180,"elapsed":393,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"b1a84794-2f01-44b8-c6e4-b2dd2cfeb37d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 512])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MuOf5O1Ipg2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723945760034,"user_tz":180,"elapsed":911,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"698b805a-2e80-484a-9b01-5d8615c6d5b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Self-attention na sequência de destino\n","        self_attn_output = self.self_attention(x, x, x, trg_mask)\n","        x = self.norm1(x + self.dropout(self_attn_output))\n","\n","        # Cross-attention entre a saída do self-attention e a saída do encoder\n","        cross_attn_output = self.cross_attention(x, enc_out, enc_out, src_mask)\n","        x = self.norm2(x + self.dropout(cross_attn_output))\n","\n","        # Feed-forward\n","        ffn_output = self.ffn(x)\n","        x = self.norm3(x + self.dropout(ffn_output))\n","\n","        return x\n","\n","\n","decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","enc_out = torch.randn(32, 50, d_model)\n","\n","output = decoder_layer(input_tensor, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUYuiaaNIpg2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723945784199,"user_tz":180,"elapsed":5489,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"e0da52bc-2ee1-4472-98df-c711169fb2db"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(trg_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do decoder\n","        for layer in self.layers:\n","            x = layer(x, enc_out, src_mask, trg_mask)\n","\n","        out = self.fc_out(x)\n","        return out\n","\n","\n","trg_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","decoder = Decoder(trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","trg_seq = torch.randint(0, trg_vocab_size, (32, 100))\n","enc_out = torch.randn(32, 100, d_model)\n","\n","output = decoder(trg_seq, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p95HxUvQIpg3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723945824708,"user_tz":180,"elapsed":8595,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"67502cae-49d9-43bc-8792-6329763d0ec0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Transformer Completo\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_encoder_layers, d_ff, max_len, dropout)\n","        self.decoder = Decoder(trg_vocab_size, d_model, num_heads, num_decoder_layers, d_ff, max_len, dropout)\n","\n","    def generate_mask(self, src, trg):\n","        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n","        trg_mask = (trg != 0).unsqueeze(1).unsqueeze(3)\n","        seq_length = trg.size(1)\n","        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        trg_mask = trg_mask & nopeak_mask\n","        return src_mask, trg_mask\n","\n","    def forward(self, src, trg, src_mask=None, trg_mask=None):\n","        src_mask, trg_mask = self.generate_mask(src, trg)\n","        enc_out = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n","        return out\n","\n","\n","src_vocab_size = 1000\n","trg_vocab_size = 1000\n","d_model = 512\n","num_heads = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","d_ff = 2048\n","max_len = 100\n","\n","transformer = Transformer(src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","src_seq = torch.randint(0, src_vocab_size, (batch_size, 100))\n","trg_seq = torch.randint(0, trg_vocab_size, (batch_size, 100))\n","\n","output = transformer(src_seq, trg_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, target_sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9LqcSDXQIpg3"},"outputs":[],"source":["# Gerando as máscaras de forma separada\n","\n","def create_padding_mask(seq):\n","    return (seq != 0).unsqueeze(1).unsqueeze(2).type(torch.uint8)  # Cria uma máscara para posições de preenchimento\n","\n","def create_look_ahead_mask(size):\n","    mask = (1 - torch.triu(torch.ones(size, size), diagonal=1)).type(torch.uint8)\n","    return mask  # Cria uma máscara triangular para impedir a atenção em tokens futuros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaMrrqfcIpg4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723945855019,"user_tz":180,"elapsed":388,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"27fb76a6-1846-4816-b6f9-e72a264085aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1, 1, 0, 1, 0]]]], dtype=torch.uint8)\n"]}],"source":["seq = torch.tensor([[1, 2, 0, 4, 0]])\n","padding_mask = create_padding_mask(seq)\n","print(padding_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXPraQlIIpg4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723945861913,"user_tz":180,"elapsed":406,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"a04f7a15-4072-42c5-b812-e7fbed9b22bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 0, 0, 0, 0],\n","        [1, 1, 0, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]], dtype=torch.uint8)\n"]}],"source":["look_ahead_mask = create_look_ahead_mask(5)\n","print(look_ahead_mask)"]},{"cell_type":"markdown","metadata":{"id":"14kk3VcWIpg4"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"3iz7bVRPIpg-"},"source":["### Exercício 1\n","Implemente um módulo que utilize apenas o módulo Encoder para a classificação de texto em `num_classes` classes. Para a obtenção do vetor de embedding de toda a sequência que será enviado para a cabeça de classificação, faça um pooling de média através da dimensão de sequência."]},{"cell_type":"code","source":["class TextClassifier(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes, dropout=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout)\n","        self.fc = nn.Linear(d_model, num_classes)\n","\n","    def forward(self, x, mask=None):\n","        # Passa a sequência internamente por cada camada do encoder, que também já encapsula embedding, positional encoding e dropout\n","        encoder_output = self.encoder(x, mask)\n","\n","        # Aplica um pooling de média ao longo da dimensão da sequência (dimensão 1)\n","        pooling_output = torch.mean(encoder_output, dim=1)\n","\n","        # Passa o vetor pooling para a cabeça de classificação\n","        x = self.fc(pooling_output)\n","\n","        return x"],"metadata":{"id":"MccnGPz6TVbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parâmetros de exemplo\n","d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","num_classes = 10\n","\n","# Instancia o classificador de texto\n","model = TextClassifier(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes)\n","\n","# Exemplo de entrada\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))  # (batch_size, sequence_length)\n","\n","# Saída do modelo\n","output = model(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npqR2d_VYa_v","executionInfo":{"status":"ok","timestamp":1723949926923,"user_tz":180,"elapsed":2542,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"a48cc67b-3ba4-4ea9-e79f-476ccaa933b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 10])\n"]}]},{"cell_type":"markdown","source":["####**`Resposta Exercício 1`**:\n","* O código acima define a classe TextClassifier como um transformer de encoder e uma camada linear fully connected no final para fazer a classificação.\n","* O encoder processa a entrada, o pooling de média obtém uma representação fixa, e a camada linear gera a classificação.\n","----------------------------------------------------------------------"],"metadata":{"id":"PJWnMafHbgah"}},{"cell_type":"markdown","metadata":{"id":"0jGQnuCsIpg_"},"source":["### Exercício 2\n","Vamos implementar um modelo baseado em stack de decoders. Uma vez que não é necessário cross-attention, pois não há encoders, utilize o módulo `EncoderLayer`. O tamanho do vocabulário deverá ser de 50257, o tamanho dos embeddings de 768, 12 cabeças de atenção, 12 camadas, dimensão da camada feedforward de 3072 e tamanho máximo de sequência 1024. Em seguida, teste com valores aleatórios simulando uma sequência de tokens."]},{"cell_type":"code","source":["# Definição do modelo baseado em stack de EncoderLayers\n","class StackDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do decoder (EncoderLayer)\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        # Camada de saída\n","        out = self.fc_out(x)\n","        return out"],"metadata":{"id":"_jqd8dpJgrtd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parâmetros do modelo\n","vocab_size = 50257\n","d_model = 768\n","num_heads = 12\n","num_layers = 12\n","d_ff = 3072\n","max_len = 1024\n","dropout = 0.1\n","\n","# Inicializando o modelo\n","model = StackDecoder(vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout)\n","\n","# Simulando uma sequência de tokens\n","trg_seq = torch.randint(0, vocab_size, (32, 100))  # (batch_size, sequence_length)\n","\n","# Passando a sequência pelo modelo\n","output = model(trg_seq)\n","\n","print(output.shape)  # Esperado: (batch_size, sequence_length, vocab_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab9kSDOwguNw","executionInfo":{"status":"ok","timestamp":1723951943479,"user_tz":180,"elapsed":17263,"user":{"displayName":"ALLAN PEDREIRA SANTOS BISPO","userId":"12665583498146225637"}},"outputId":"e608fcd8-8a69-4b6a-ef81-f8f859e47f6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 50257])\n"]}]},{"cell_type":"markdown","source":["####**`Resposta Exercício 2`**:\n","* 'StackDecoder' define um modelo de transformer usando camadas de `EncoderLayer` ao invés de 'DecoderLayer' para processamento de tokens, adaptado sem cross-attention e com parâmetros específicos para tamanho do vocabulário e embedding.\n","\n","* A arquitetura inclui uma camada de embedding, codificação posicional e uma pilha de camadas `EncoderLayer`, com a saída final projetada para o tamanho do vocabulário, 50257."],"metadata":{"id":"DG_85rgBjC-m"}}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[{"file_id":"https://github.com/silvaan/topicos_contemporaneos/blob/main/Part%202%20-%20LLMs/04%20-%20Transformers.ipynb","timestamp":1723945102606}]}},"nbformat":4,"nbformat_minor":0}